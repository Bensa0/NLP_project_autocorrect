{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import gensim\n",
    "file_name = 'ALICE.txt'\n",
    "data=open(file_name)\n",
    "corona_data = [text for text in data if text.count(' ') >= 2]\n",
    "vectorize = Tokenizer()\n",
    "vectorize.fit_on_texts(corona_data)\n",
    "corona_data = vectorize.texts_to_sequences(corona_data)\n",
    "total_vocab = sum(len(s) for s in corona_data)\n",
    "word_count = len(vectorize.word_index) + 1\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " \"'\": 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'she': 6,\n",
       " 'of': 7,\n",
       " 'it': 8,\n",
       " 'said': 9,\n",
       " 'alice': 10,\n",
       " 'in': 11,\n",
       " 'was': 12,\n",
       " 'you': 13,\n",
       " 'i': 14,\n",
       " 'that': 15,\n",
       " 'as': 16,\n",
       " 'her': 17,\n",
       " 'at': 18,\n",
       " 'on': 19,\n",
       " 'with': 20,\n",
       " 'all': 21,\n",
       " 'had': 22,\n",
       " 'be': 23,\n",
       " 'for': 24,\n",
       " 'so': 25,\n",
       " 'very': 26,\n",
       " 'not': 27,\n",
       " 'but': 28,\n",
       " 'this': 29,\n",
       " 'little': 30,\n",
       " \"'i\": 31,\n",
       " 'they': 32,\n",
       " 'out': 33,\n",
       " 'he': 34,\n",
       " 'is': 35,\n",
       " 'down': 36,\n",
       " 'what': 37,\n",
       " 'up': 38,\n",
       " 'one': 39,\n",
       " 'his': 40,\n",
       " 'about': 41,\n",
       " 'them': 42,\n",
       " 'like': 43,\n",
       " 'were': 44,\n",
       " 'herself': 45,\n",
       " 'know': 46,\n",
       " 'then': 47,\n",
       " 'went': 48,\n",
       " 'again': 49,\n",
       " 'would': 50,\n",
       " 'no': 51,\n",
       " 'have': 52,\n",
       " 'could': 53,\n",
       " 'if': 54,\n",
       " 'thought': 55,\n",
       " 'when': 56,\n",
       " 'do': 57,\n",
       " 'or': 58,\n",
       " 'there': 59,\n",
       " 'time': 60,\n",
       " 'into': 61,\n",
       " 'see': 62,\n",
       " 'me': 63,\n",
       " 'queen': 64,\n",
       " 'off': 65,\n",
       " 'did': 66,\n",
       " 'your': 67,\n",
       " 'king': 68,\n",
       " 'began': 69,\n",
       " 'by': 70,\n",
       " 'its': 71,\n",
       " \"'and\": 72,\n",
       " 'way': 73,\n",
       " 'an': 74,\n",
       " 'mock': 75,\n",
       " 'quite': 76,\n",
       " 'my': 77,\n",
       " 'who': 78,\n",
       " \"don't\": 79,\n",
       " 'hatter': 80,\n",
       " 'turtle': 81,\n",
       " 'gryphon': 82,\n",
       " 'think': 83,\n",
       " 'how': 84,\n",
       " 'much': 85,\n",
       " 'their': 86,\n",
       " 'say': 87,\n",
       " 'some': 88,\n",
       " 'now': 89,\n",
       " 'just': 90,\n",
       " 'first': 91,\n",
       " 'thing': 92,\n",
       " 'here': 93,\n",
       " 'head': 94,\n",
       " 'go': 95,\n",
       " 'more': 96,\n",
       " 'voice': 97,\n",
       " 'are': 98,\n",
       " 'rabbit': 99,\n",
       " 'only': 100,\n",
       " 'looked': 101,\n",
       " 'never': 102,\n",
       " 'which': 103,\n",
       " 'got': 104,\n",
       " 'get': 105,\n",
       " 'must': 106,\n",
       " 'him': 107,\n",
       " 'mouse': 108,\n",
       " 'after': 109,\n",
       " 'such': 110,\n",
       " 'round': 111,\n",
       " 'came': 112,\n",
       " 'other': 113,\n",
       " \"'you\": 114,\n",
       " 'tone': 115,\n",
       " 'well': 116,\n",
       " 'over': 117,\n",
       " \"i'm\": 118,\n",
       " \"'but\": 119,\n",
       " 'duchess': 120,\n",
       " 'dormouse': 121,\n",
       " 'before': 122,\n",
       " 'great': 123,\n",
       " 'been': 124,\n",
       " 'any': 125,\n",
       " 'back': 126,\n",
       " 'two': 127,\n",
       " 'cat': 128,\n",
       " \"'what\": 129,\n",
       " 'from': 130,\n",
       " 'can': 131,\n",
       " 'large': 132,\n",
       " \"it's\": 133,\n",
       " 'will': 134,\n",
       " 'last': 135,\n",
       " 'march': 136,\n",
       " 'once': 137,\n",
       " 'long': 138,\n",
       " 'looking': 139,\n",
       " 'put': 140,\n",
       " 'come': 141,\n",
       " 'right': 142,\n",
       " 'white': 143,\n",
       " 'found': 144,\n",
       " 'next': 145,\n",
       " 'things': 146,\n",
       " 'door': 147,\n",
       " \"'it\": 148,\n",
       " 'heard': 149,\n",
       " 'hare': 150,\n",
       " 'nothing': 151,\n",
       " 'made': 152,\n",
       " 'eyes': 153,\n",
       " 'moment': 154,\n",
       " 'tell': 155,\n",
       " 'replied': 156,\n",
       " 'day': 157,\n",
       " 'dear': 158,\n",
       " 'look': 159,\n",
       " 'might': 160,\n",
       " 'seemed': 161,\n",
       " 'going': 162,\n",
       " 'make': 163,\n",
       " 'good': 164,\n",
       " 'should': 165,\n",
       " 'three': 166,\n",
       " \"can't\": 167,\n",
       " 'caterpillar': 168,\n",
       " 'upon': 169,\n",
       " 'poor': 170,\n",
       " \"i'll\": 171,\n",
       " 'too': 172,\n",
       " 'rather': 173,\n",
       " 'soon': 174,\n",
       " 'away': 175,\n",
       " 'without': 176,\n",
       " 'while': 177,\n",
       " 'course': 178,\n",
       " 'took': 179,\n",
       " 'yet': 180,\n",
       " \"'it's\": 181,\n",
       " \"'oh\": 182,\n",
       " 'shall': 183,\n",
       " \"'well\": 184,\n",
       " 'felt': 185,\n",
       " 'than': 186,\n",
       " 'half': 187,\n",
       " 'same': 188,\n",
       " \"won't\": 189,\n",
       " 'added': 190,\n",
       " 'getting': 191,\n",
       " 'oh': 192,\n",
       " 'another': 193,\n",
       " \"'why\": 194,\n",
       " 'words': 195,\n",
       " 'wish': 196,\n",
       " 'ever': 197,\n",
       " \"'if\": 198,\n",
       " \"'the\": 199,\n",
       " 'jury': 200,\n",
       " \"i've\": 201,\n",
       " 'sort': 202,\n",
       " 'hand': 203,\n",
       " 'find': 204,\n",
       " 'cried': 205,\n",
       " 'minute': 206,\n",
       " 'sure': 207,\n",
       " \"'i'm\": 208,\n",
       " 'feet': 209,\n",
       " 'take': 210,\n",
       " 'tried': 211,\n",
       " 'anything': 212,\n",
       " 'even': 213,\n",
       " 'tea': 214,\n",
       " 'however': 215,\n",
       " 'curious': 216,\n",
       " 'being': 217,\n",
       " 'till': 218,\n",
       " 'we': 219,\n",
       " 'old': 220,\n",
       " 'use': 221,\n",
       " 'wonder': 222,\n",
       " 'why': 223,\n",
       " 'house': 224,\n",
       " 'end': 225,\n",
       " \"that's\": 226,\n",
       " 'table': 227,\n",
       " 'soup': 228,\n",
       " 'eat': 229,\n",
       " 'question': 230,\n",
       " 'side': 231,\n",
       " 'sat': 232,\n",
       " \"there's\": 233,\n",
       " 'enough': 234,\n",
       " 'something': 235,\n",
       " 'asked': 236,\n",
       " 'court': 237,\n",
       " 'ran': 238,\n",
       " 'under': 239,\n",
       " 'spoke': 240,\n",
       " \"you're\": 241,\n",
       " 'turned': 242,\n",
       " 'high': 243,\n",
       " 'garden': 244,\n",
       " 'indeed': 245,\n",
       " \"doesn't\": 246,\n",
       " \"'how\": 247,\n",
       " \"'that's\": 248,\n",
       " 'seen': 249,\n",
       " 'near': 250,\n",
       " 'idea': 251,\n",
       " 'please': 252,\n",
       " 'air': 253,\n",
       " 'talking': 254,\n",
       " 'saying': 255,\n",
       " 'low': 256,\n",
       " 'knew': 257,\n",
       " 'face': 258,\n",
       " \"'come\": 259,\n",
       " 'gave': 260,\n",
       " 'hastily': 261,\n",
       " 'am': 262,\n",
       " 'done': 263,\n",
       " \"'that\": 264,\n",
       " 'called': 265,\n",
       " 'arm': 266,\n",
       " 'beginning': 267,\n",
       " 'hear': 268,\n",
       " 'itself': 269,\n",
       " 'ought': 270,\n",
       " 'saw': 271,\n",
       " 'let': 272,\n",
       " 'through': 273,\n",
       " \"didn't\": 274,\n",
       " 'perhaps': 275,\n",
       " 'remember': 276,\n",
       " 'bit': 277,\n",
       " 'trying': 278,\n",
       " 'anxiously': 279,\n",
       " 'set': 280,\n",
       " 'these': 281,\n",
       " 'talk': 282,\n",
       " 'us': 283,\n",
       " 'both': 284,\n",
       " \"'i've\": 285,\n",
       " 'baby': 286,\n",
       " 'mad': 287,\n",
       " 'suddenly': 288,\n",
       " 'close': 289,\n",
       " 'still': 290,\n",
       " 'people': 291,\n",
       " 'cats': 292,\n",
       " 'behind': 293,\n",
       " 'certainly': 294,\n",
       " \"'no\": 295,\n",
       " 'size': 296,\n",
       " 'left': 297,\n",
       " 'far': 298,\n",
       " 'kept': 299,\n",
       " 'used': 300,\n",
       " 'change': 301,\n",
       " 'always': 302,\n",
       " 'dodo': 303,\n",
       " 'whole': 304,\n",
       " 'bill': 305,\n",
       " 'room': 306,\n",
       " 'gone': 307,\n",
       " 'footman': 308,\n",
       " 'cook': 309,\n",
       " 'dance': 310,\n",
       " 'chapter': 311,\n",
       " \"wouldn't\": 312,\n",
       " 'many': 313,\n",
       " 'among': 314,\n",
       " 'afraid': 315,\n",
       " 'begin': 316,\n",
       " 'because': 317,\n",
       " 'finished': 318,\n",
       " 'best': 319,\n",
       " 'game': 320,\n",
       " 'hardly': 321,\n",
       " 'grow': 322,\n",
       " 'speak': 323,\n",
       " 'deal': 324,\n",
       " 'queer': 325,\n",
       " 'everything': 326,\n",
       " 'try': 327,\n",
       " 'hands': 328,\n",
       " 'sea': 329,\n",
       " 'suppose': 330,\n",
       " 'silence': 331,\n",
       " \"'of\": 332,\n",
       " 'turning': 333,\n",
       " \"'yes\": 334,\n",
       " 'where': 335,\n",
       " 'better': 336,\n",
       " \"'then\": 337,\n",
       " 'may': 338,\n",
       " 'pigeon': 339,\n",
       " 'majesty': 340,\n",
       " 'book': 341,\n",
       " 'mind': 342,\n",
       " 'whether': 343,\n",
       " 'though': 344,\n",
       " 'glad': 345,\n",
       " 'else': 346,\n",
       " 'dinah': 347,\n",
       " 'every': 348,\n",
       " \"alice's\": 349,\n",
       " 'minutes': 350,\n",
       " 'child': 351,\n",
       " 'makes': 352,\n",
       " 'growing': 353,\n",
       " 'life': 354,\n",
       " 'pool': 355,\n",
       " \"'a\": 356,\n",
       " 'gloves': 357,\n",
       " \"'not\": 358,\n",
       " \"'we\": 359,\n",
       " \"wasn't\": 360,\n",
       " 'beautiful': 361,\n",
       " 'pig': 362,\n",
       " 'sitting': 363,\n",
       " 'having': 364,\n",
       " 'own': 365,\n",
       " 'hurried': 366,\n",
       " 'lessons': 367,\n",
       " 'heads': 368,\n",
       " 'word': 369,\n",
       " 'ask': 370,\n",
       " \"'now\": 371,\n",
       " 'sight': 372,\n",
       " 'walked': 373,\n",
       " 'glass': 374,\n",
       " 'small': 375,\n",
       " 'opened': 376,\n",
       " 'really': 377,\n",
       " 'bottle': 378,\n",
       " 'hurry': 379,\n",
       " 'read': 380,\n",
       " 'children': 381,\n",
       " 'waited': 382,\n",
       " 'tears': 383,\n",
       " 'box': 384,\n",
       " \"'they\": 385,\n",
       " 'foot': 386,\n",
       " 'fan': 387,\n",
       " 'nearly': 388,\n",
       " 'birds': 389,\n",
       " 'party': 390,\n",
       " 'rest': 391,\n",
       " 'mean': 392,\n",
       " 'keep': 393,\n",
       " 'mouth': 394,\n",
       " \"they're\": 395,\n",
       " 'remarked': 396,\n",
       " 'remark': 397,\n",
       " 'soldiers': 398,\n",
       " 'witness': 399,\n",
       " 'either': 400,\n",
       " 'coming': 401,\n",
       " 'name': 402,\n",
       " \"couldn't\": 403,\n",
       " 'answer': 404,\n",
       " 'matter': 405,\n",
       " 'hall': 406,\n",
       " 'key': 407,\n",
       " 'rate': 408,\n",
       " 'those': 409,\n",
       " 'few': 410,\n",
       " 'waiting': 411,\n",
       " 'against': 412,\n",
       " 'want': 413,\n",
       " 'give': 414,\n",
       " 'help': 415,\n",
       " 'different': 416,\n",
       " 'thinking': 417,\n",
       " 'mine': 418,\n",
       " 'tail': 419,\n",
       " 'offended': 420,\n",
       " 'conversation': 421,\n",
       " 'creatures': 422,\n",
       " 'continued': 423,\n",
       " 'believe': 424,\n",
       " 'angrily': 425,\n",
       " 'shook': 426,\n",
       " 'least': 427,\n",
       " 'reason': 428,\n",
       " 'together': 429,\n",
       " 'shouted': 430,\n",
       " 'turn': 431,\n",
       " 'timidly': 432,\n",
       " 'repeated': 433,\n",
       " 'puzzled': 434,\n",
       " 'interrupted': 435,\n",
       " 'join': 436,\n",
       " 'sister': 437,\n",
       " 'feel': 438,\n",
       " 'making': 439,\n",
       " 'watch': 440,\n",
       " 'slowly': 441,\n",
       " 'happen': 442,\n",
       " 'noticed': 443,\n",
       " 'top': 444,\n",
       " 'four': 445,\n",
       " 'opportunity': 446,\n",
       " 'seem': 447,\n",
       " \"'do\": 448,\n",
       " 'dry': 449,\n",
       " 'bright': 450,\n",
       " 'fact': 451,\n",
       " \"'in\": 452,\n",
       " 'followed': 453,\n",
       " 'croquet': 454,\n",
       " 'lying': 455,\n",
       " 'work': 456,\n",
       " 'ready': 457,\n",
       " 'hard': 458,\n",
       " 'changed': 459,\n",
       " 'five': 460,\n",
       " 'live': 461,\n",
       " 'play': 462,\n",
       " 'beg': 463,\n",
       " 'our': 464,\n",
       " \"you'd\": 465,\n",
       " 'eagerly': 466,\n",
       " 'meaning': 467,\n",
       " 'explain': 468,\n",
       " 'running': 469,\n",
       " 'story': 470,\n",
       " 'place': 471,\n",
       " 'appeared': 472,\n",
       " 'wood': 473,\n",
       " 'mushroom': 474,\n",
       " \"haven't\": 475,\n",
       " 'most': 476,\n",
       " 'tree': 477,\n",
       " 'fish': 478,\n",
       " 'asleep': 479,\n",
       " 'butter': 480,\n",
       " 'hearts': 481,\n",
       " 'gardeners': 482,\n",
       " 'knave': 483,\n",
       " \"'off\": 484,\n",
       " 'whiting': 485,\n",
       " 'tired': 486,\n",
       " 'hot': 487,\n",
       " 'pocket': 488,\n",
       " 'world': 489,\n",
       " 'deep': 490,\n",
       " 'fall': 491,\n",
       " 'listen': 492,\n",
       " 'distance': 493,\n",
       " \"it'll\": 494,\n",
       " 'fancy': 495,\n",
       " 'manage': 496,\n",
       " 'begun': 497,\n",
       " 'dream': 498,\n",
       " 'middle': 499,\n",
       " 'wondering': 500,\n",
       " 'golden': 501,\n",
       " 'open': 502,\n",
       " 'larger': 503,\n",
       " 'happened': 504,\n",
       " 'neck': 505,\n",
       " 'feeling': 506,\n",
       " \"'for\": 507,\n",
       " 'leave': 508,\n",
       " 'generally': 509,\n",
       " 'eye': 510,\n",
       " 'surprised': 511,\n",
       " 'shoes': 512,\n",
       " 'myself': 513,\n",
       " 'kind': 514,\n",
       " 'yourself': 515,\n",
       " 'hair': 516,\n",
       " 'goes': 517,\n",
       " 'learn': 518,\n",
       " 'frightened': 519,\n",
       " \"hadn't\": 520,\n",
       " 'william': 521,\n",
       " 'history': 522,\n",
       " \"'as\": 523,\n",
       " \"'are\": 524,\n",
       " 'has': 525,\n",
       " 'trial': 526,\n",
       " \"'he\": 527,\n",
       " \"i'd\": 528,\n",
       " 'window': 529,\n",
       " 'stood': 530,\n",
       " 'does': 531,\n",
       " 'grown': 532,\n",
       " 'business': 533,\n",
       " \"'so\": 534,\n",
       " 'trees': 535,\n",
       " 'each': 536,\n",
       " \"isn't\": 537,\n",
       " 'nose': 538,\n",
       " 'serpent': 539,\n",
       " 'draw': 540,\n",
       " 'pepper': 541,\n",
       " 'ground': 542,\n",
       " \"'there's\": 543,\n",
       " 'pleased': 544,\n",
       " 'song': 545,\n",
       " 'twinkle': 546,\n",
       " \"queen's\": 547,\n",
       " 'hedgehog': 548,\n",
       " 'moral': 549,\n",
       " 'lobster': 550,\n",
       " 'lobsters': 551,\n",
       " 'oop': 552,\n",
       " 'tarts': 553,\n",
       " 'slates': 554,\n",
       " 'evidence': 555,\n",
       " 'trouble': 556,\n",
       " 'late': 557,\n",
       " 'fell': 558,\n",
       " 'somebody': 559,\n",
       " 'nice': 560,\n",
       " 'written': 561,\n",
       " 'leaves': 562,\n",
       " 'jumped': 563,\n",
       " 'roof': 564,\n",
       " 'inches': 565,\n",
       " 'along': 566,\n",
       " 'marked': 567,\n",
       " 'hold': 568,\n",
       " 'forgotten': 569,\n",
       " 'almost': 570,\n",
       " 'english': 571,\n",
       " \"'or\": 572,\n",
       " 'stop': 573,\n",
       " 'himself': 574,\n",
       " 'sir': 575,\n",
       " 'times': 576,\n",
       " 'repeat': 577,\n",
       " 'grin': 578,\n",
       " 'chin': 579,\n",
       " 'understand': 580,\n",
       " 'pardon': 581,\n",
       " \"'don't\": 582,\n",
       " 'trembling': 583,\n",
       " 'subject': 584,\n",
       " 'sit': 585,\n",
       " 'lory': 586,\n",
       " 'race': 587,\n",
       " 'politely': 588,\n",
       " 'melancholy': 589,\n",
       " 'liked': 590,\n",
       " 'exactly': 591,\n",
       " 'piece': 592,\n",
       " 'others': 593,\n",
       " \"'you're\": 594,\n",
       " 'nobody': 595,\n",
       " 'executed': 596,\n",
       " 'broken': 597,\n",
       " 'chimney': 598,\n",
       " 'full': 599,\n",
       " 'sharp': 600,\n",
       " 'guinea': 601,\n",
       " 'pigs': 602,\n",
       " 'puppy': 603,\n",
       " 'arms': 604,\n",
       " \"'who\": 605,\n",
       " 'father': 606,\n",
       " 'youth': 607,\n",
       " 'sleep': 608,\n",
       " \"you've\": 609,\n",
       " 'silent': 610,\n",
       " 'sneezing': 611,\n",
       " 'between': 612,\n",
       " 'told': 613,\n",
       " 'ear': 614,\n",
       " 'cheshire': 615,\n",
       " 'everybody': 616,\n",
       " 'dreadfully': 617,\n",
       " 'writing': 618,\n",
       " 'bread': 619,\n",
       " 'sing': 620,\n",
       " 'exclaimed': 621,\n",
       " 'school': 622,\n",
       " 'adventures': 623,\n",
       " 'soo': 624,\n",
       " 'e': 625,\n",
       " 'hole': 626,\n",
       " 'twice': 627,\n",
       " 'sleepy': 628,\n",
       " 'across': 629,\n",
       " 'curiosity': 630,\n",
       " 'passed': 631,\n",
       " 'home': 632,\n",
       " 'likely': 633,\n",
       " 'walk': 634,\n",
       " 'new': 635,\n",
       " 'asking': 636,\n",
       " 'night': 637,\n",
       " 'sometimes': 638,\n",
       " 'walking': 639,\n",
       " 'ears': 640,\n",
       " 'shut': 641,\n",
       " 'simple': 642,\n",
       " 'cut': 643,\n",
       " 'finger': 644,\n",
       " 'ten': 645,\n",
       " 'nervous': 646,\n",
       " 'altogether': 647,\n",
       " 'remembered': 648,\n",
       " \"'to\": 649,\n",
       " 'happens': 650,\n",
       " \"shan't\": 651,\n",
       " 'pair': 652,\n",
       " 'nonsense': 653,\n",
       " 'kid': 654,\n",
       " 'dropped': 655,\n",
       " 'usual': 656,\n",
       " 'morning': 657,\n",
       " 'seven': 658,\n",
       " 'wrong': 659,\n",
       " 'sounded': 660,\n",
       " 'strange': 661,\n",
       " 'seems': 662,\n",
       " 'stay': 663,\n",
       " 'sudden': 664,\n",
       " 'water': 665,\n",
       " 'case': 666,\n",
       " 'number': 667,\n",
       " 'swam': 668,\n",
       " 'nearer': 669,\n",
       " \"'would\": 670,\n",
       " 'speaking': 671,\n",
       " 'shrill': 672,\n",
       " 'angry': 673,\n",
       " 'fetch': 674,\n",
       " 'crowded': 675,\n",
       " 'important': 676,\n",
       " 'notice': 677,\n",
       " \"'one\": 678,\n",
       " 'chorus': 679,\n",
       " 'dare': 680,\n",
       " 'confusion': 681,\n",
       " 'call': 682,\n",
       " 'finish': 683,\n",
       " 'impatiently': 684,\n",
       " 'sighed': 685,\n",
       " 'temper': 686,\n",
       " 'young': 687,\n",
       " 'doing': 688,\n",
       " 'direction': 689,\n",
       " 'interesting': 690,\n",
       " 'become': 691,\n",
       " \"'when\": 692,\n",
       " 'write': 693,\n",
       " \"shouldn't\": 694,\n",
       " 'taking': 695,\n",
       " 'shriek': 696,\n",
       " 'loud': 697,\n",
       " 'drew': 698,\n",
       " 'sky': 699,\n",
       " 'instantly': 700,\n",
       " \"'i'll\": 701,\n",
       " 'surprise': 702,\n",
       " 'lizard': 703,\n",
       " 'height': 704,\n",
       " 'quietly': 705,\n",
       " 'hookah': 706,\n",
       " 'man': 707,\n",
       " 'stand': 708,\n",
       " 'often': 709,\n",
       " 'eggs': 710,\n",
       " 'meant': 711,\n",
       " 'waving': 712,\n",
       " \"'very\": 713,\n",
       " 'treacle': 714,\n",
       " 'faces': 715,\n",
       " 'procession': 716,\n",
       " 'pack': 717,\n",
       " 'knee': 718,\n",
       " 'whispered': 719,\n",
       " 'flamingo': 720,\n",
       " 'executioner': 721,\n",
       " 'evening': 722,\n",
       " 'pictures': 723,\n",
       " 'worth': 724,\n",
       " 'natural': 725,\n",
       " 'sides': 726,\n",
       " 'fear': 727,\n",
       " 'managed': 728,\n",
       " \"they'll\": 729,\n",
       " 'true': 730,\n",
       " 'fallen': 731,\n",
       " 'aloud': 732,\n",
       " 'earth': 733,\n",
       " 'several': 734,\n",
       " 'sound': 735,\n",
       " 'girl': 736,\n",
       " 'miss': 737,\n",
       " 'mice': 738,\n",
       " 'bats': 739,\n",
       " 'passage': 740,\n",
       " 'corner': 741,\n",
       " 'sadly': 742,\n",
       " 'except': 743,\n",
       " 'tiny': 744,\n",
       " 'alas': 745,\n",
       " 'second': 746,\n",
       " 'led': 747,\n",
       " 'shoulders': 748,\n",
       " \"'which\": 749,\n",
       " 'paper': 750,\n",
       " 'taught': 751,\n",
       " 'deeply': 752,\n",
       " 'drink': 753,\n",
       " 'ventured': 754,\n",
       " 'reach': 755,\n",
       " 'sharply': 756,\n",
       " 'severely': 757,\n",
       " 'fond': 758,\n",
       " 'person': 759,\n",
       " 'care': 760,\n",
       " 'nine': 761,\n",
       " 'until': 762,\n",
       " 'savage': 763,\n",
       " 'violently': 764,\n",
       " 'age': 765,\n",
       " 'mabel': 766,\n",
       " \"she's\": 767,\n",
       " 'puzzling': 768,\n",
       " 'twelve': 769,\n",
       " 'capital': 770,\n",
       " 'alone': 771,\n",
       " \"rabbit's\": 772,\n",
       " 'shrinking': 773,\n",
       " 'escape': 774,\n",
       " 'french': 775,\n",
       " 'sentence': 776,\n",
       " 'fire': 777,\n",
       " 'paws': 778,\n",
       " \"'there\": 779,\n",
       " 'says': 780,\n",
       " 'pale': 781,\n",
       " \"you'll\": 782,\n",
       " 'animals': 783,\n",
       " 'duck': 784,\n",
       " 'tale': 785,\n",
       " 'uncomfortable': 786,\n",
       " 'argument': 787,\n",
       " 'wanted': 788,\n",
       " 'frowning': 789,\n",
       " 'means': 790,\n",
       " 'solemnly': 791,\n",
       " 'prizes': 792,\n",
       " 'pointing': 793,\n",
       " 'confused': 794,\n",
       " \"'only\": 795,\n",
       " 'short': 796,\n",
       " 'bowed': 797,\n",
       " 'judge': 798,\n",
       " 'breath': 799,\n",
       " 'reply': 800,\n",
       " \"'please\": 801,\n",
       " \"'ah\": 802,\n",
       " \"'hold\": 803,\n",
       " 'tongue': 804,\n",
       " 'particular': 805,\n",
       " 'moved': 806,\n",
       " 'since': 807,\n",
       " 'swim': 808,\n",
       " 'vanished': 809,\n",
       " 'ann': 810,\n",
       " 'run': 811,\n",
       " 'chance': 812,\n",
       " 'answered': 813,\n",
       " 'outside': 814,\n",
       " \"'sure\": 815,\n",
       " 'yer': 816,\n",
       " 'honour': 817,\n",
       " 'sounds': 818,\n",
       " 'hearing': 819,\n",
       " \"bill's\": 820,\n",
       " 'slate': 821,\n",
       " 'master': 822,\n",
       " 'dead': 823,\n",
       " 'doubt': 824,\n",
       " 'lay': 825,\n",
       " 'crowd': 826,\n",
       " 'held': 827,\n",
       " \"'is\": 828,\n",
       " 'plan': 829,\n",
       " 'difficulty': 830,\n",
       " 'stick': 831,\n",
       " 'grass': 832,\n",
       " 'perfectly': 833,\n",
       " 'none': 834,\n",
       " 'questions': 835,\n",
       " 'decidedly': 836,\n",
       " 'thoughtfully': 837,\n",
       " 'green': 838,\n",
       " 'screamed': 839,\n",
       " 'indignantly': 840,\n",
       " 'taken': 841,\n",
       " 'otherwise': 842,\n",
       " 'dish': 843,\n",
       " 'days': 844,\n",
       " 'kitchen': 845,\n",
       " 'jumping': 846,\n",
       " 'carried': 847,\n",
       " 'hours': 848,\n",
       " 'busily': 849,\n",
       " 'beat': 850,\n",
       " 'wow': 851,\n",
       " 'creature': 852,\n",
       " 'grunted': 853,\n",
       " 'less': 854,\n",
       " \"'call\": 855,\n",
       " \"'i'd\": 856,\n",
       " 'fast': 857,\n",
       " 'shoulder': 858,\n",
       " 'twinkling': 859,\n",
       " 'sigh': 860,\n",
       " 'bottom': 861,\n",
       " 'begins': 862,\n",
       " 'rose': 863,\n",
       " 'rule': 864,\n",
       " \"'she\": 865,\n",
       " 'arches': 866,\n",
       " 'players': 867,\n",
       " 'hers': 868,\n",
       " 'quadrille': 869,\n",
       " 'porpoise': 870,\n",
       " 'mouths': 871,\n",
       " 'beau': 872,\n",
       " 'ootiful': 873,\n",
       " 'jurors': 874,\n",
       " 'verdict': 875,\n",
       " 'officers': 876,\n",
       " 'suppressed': 877,\n",
       " 'jurymen': 878,\n",
       " \"'nothing\": 879,\n",
       " 'verses': 880,\n",
       " 'bank': 881,\n",
       " 'peeped': 882,\n",
       " 'reading': 883,\n",
       " 'considering': 884,\n",
       " 'stupid': 885,\n",
       " 'dark': 886,\n",
       " 'filled': 887,\n",
       " 'past': 888,\n",
       " 'stairs': 889,\n",
       " 'miles': 890,\n",
       " 'somewhere': 891,\n",
       " 'knowledge': 892,\n",
       " 'grand': 893,\n",
       " 'funny': 894,\n",
       " 'listening': 895,\n",
       " \"she'll\": 896,\n",
       " 'hope': 897,\n",
       " 'catch': 898,\n",
       " 'bat': 899,\n",
       " 'hurt': 900,\n",
       " 'lost': 901,\n",
       " 'longer': 902,\n",
       " 'hanging': 903,\n",
       " 'delight': 904,\n",
       " 'hoping': 905,\n",
       " 'rules': 906,\n",
       " \"'drink\": 907,\n",
       " 'red': 908,\n",
       " 'knife': 909,\n",
       " 'certain': 910,\n",
       " 'later': 911,\n",
       " 'finding': 912,\n",
       " 'further': 913,\n",
       " 'candle': 914,\n",
       " 'decided': 915,\n",
       " 'possibly': 916,\n",
       " 'legs': 917,\n",
       " 'cake': 918,\n",
       " 'smaller': 919,\n",
       " 'holding': 920,\n",
       " 'remained': 921,\n",
       " 'expecting': 922,\n",
       " 'dull': 923,\n",
       " 'opening': 924,\n",
       " 'dears': 925,\n",
       " 'boots': 926,\n",
       " 'directions': 927,\n",
       " 'love': 928,\n",
       " 'cry': 929,\n",
       " 'pattering': 930,\n",
       " 'muttering': 931,\n",
       " 'timid': 932,\n",
       " 'yesterday': 933,\n",
       " 'sorts': 934,\n",
       " 'besides': 935,\n",
       " \"let's\": 936,\n",
       " 'doth': 937,\n",
       " 'crossed': 938,\n",
       " 'hoarse': 939,\n",
       " 'spread': 940,\n",
       " 'gently': 941,\n",
       " 'guess': 942,\n",
       " 'cause': 943,\n",
       " 'worse': 944,\n",
       " 'slipped': 945,\n",
       " 'general': 946,\n",
       " 'digging': 947,\n",
       " \"'perhaps\": 948,\n",
       " 'notion': 949,\n",
       " 'lesson': 950,\n",
       " 'show': 951,\n",
       " 'washing': 952,\n",
       " 'nurse': 953,\n",
       " 'dogs': 954,\n",
       " 'throw': 955,\n",
       " 'passion': 956,\n",
       " \"'let\": 957,\n",
       " 'shore': 958,\n",
       " 'eaglet': 959,\n",
       " 'caucus': 960,\n",
       " 'fur': 961,\n",
       " 'cross': 962,\n",
       " 'sulky': 963,\n",
       " \"'did\": 964,\n",
       " 'frog': 965,\n",
       " 'crown': 966,\n",
       " 'move': 967,\n",
       " 'pressed': 968,\n",
       " 'voices': 969,\n",
       " 'handed': 970,\n",
       " 'gravely': 971,\n",
       " 'thimble': 972,\n",
       " 'speech': 973,\n",
       " 'cheered': 974,\n",
       " 'grave': 975,\n",
       " 'simply': 976,\n",
       " 'solemn': 977,\n",
       " 'noise': 978,\n",
       " 'choked': 979,\n",
       " 'whisper': 980,\n",
       " 'sad': 981,\n",
       " 'met': 982,\n",
       " 'attending': 983,\n",
       " 'pleaded': 984,\n",
       " 'easily': 985,\n",
       " 'joined': 986,\n",
       " 'pity': 987,\n",
       " 'crab': 988,\n",
       " 'venture': 989,\n",
       " 'carefully': 990,\n",
       " 'remarking': 991,\n",
       " 'suit': 992,\n",
       " 'mentioned': 993,\n",
       " 'guessed': 994,\n",
       " 'hunting': 995,\n",
       " 'mary': 996,\n",
       " 'mistake': 997,\n",
       " 'plate': 998,\n",
       " 'knocking': 999,\n",
       " 'real': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = vectorize.word_index\n",
    "\n",
    "vocab = []\n",
    "for key, value in my_dict.items():\n",
    "    vocab.append(key)\n",
    "\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbow_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbow_model = cbow_model(vocab_size = total_vocab, embedding_dim = 100 , window_size = window_size)\n",
    "# # Create the training data\n",
    "# X_cbow, y_cbow = generate_data_cbow(corona_data, window_size, total_vocab)\n",
    "# X_cbow.shape, y_cbow.shape\n",
    "# history = cbow_model.fit(X_cbow, y_cbow, batch_size=64, epochs=150, verbose=2)\n",
    "# cbow_model.save('cbow_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 100)            2757400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27574)             2784974   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,542,374\n",
      "Trainable params: 5,542,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cbow_model = load_model('cbow_model.h5')\n",
    "cbow_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions=100\n",
    "vect_file = open('vectors.bin' ,'w')\n",
    "vect_file.write('{} {}\\n'.format(total_vocab,dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cbow_model.get_weights()[0]\n",
    "for text, i in vectorize.word_index.items():\n",
    "    final_vec = ' '.join(map(str, list(weights[i, :])))\n",
    "    vect_file.write('{} {}\\n'.format(text, final_vec))\n",
    "vect_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = open(fname, 'r')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.strip().split()\n",
    "        word = tokens[0]\n",
    "        vec = np.array(tokens[1:], dtype=np.float32)\n",
    "        data[word] = vec\n",
    "    fin.close()\n",
    "    return data\n",
    "\n",
    "vectors = load_vectors('vectors.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_vector(text, model, vectors):\n",
    "    # Convert the input text to a list of word vectors\n",
    "    words = text.split()\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        if word in vectors:\n",
    "            vecs.append(vectors[word])\n",
    "    # Calculate the average vector for the input text\n",
    "    if vecs:\n",
    "        avg_vec = sum(vecs) / len(vecs)\n",
    "    else:\n",
    "        avg_vec = np.zeros((model.vector_size,), dtype=np.float32)\n",
    "    # Predict the output vector using the trained CBOW model\n",
    "    input_vec = avg_vec.reshape(1, -1)\n",
    "    output_vec = model.predict(input_vec)\n",
    "    return output_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vectors)\n",
    "embedding_size = len(list(vectors.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text input\n",
    "text = \"the red blind dog hit his we head\".split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the context to a vector\n",
    "context_vector = np.zeros((len(text),))\n",
    "for word in text:\n",
    "    if word in text:\n",
    "        context_vector[text.index(word)] += 1\n",
    "\n",
    "# Normalize the context vector\n",
    "context_vector /= np.linalg.norm(context_vector)\n",
    "\n",
    "# Reshape the context vector to have a shape of (1, len(vocabulary))\n",
    "context_vector = context_vector.reshape(1, len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35355339, 0.35355339, 0.35355339, 0.35355339, 0.35355339,\n",
       "        0.35355339, 0.35355339, 0.35355339]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary and word-to-id dictionary\n",
    "vocabulary = vocab\n",
    "word_to_id = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "# Define the id-to-word dictionary\n",
    "id_to_word = {i: word for word, i in my_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 618ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the id-to-word dictionary\n",
    "id_to_word = {i: word for word, i in word_to_id.items()}\n",
    "for i in range(len(vocabulary)):\n",
    "    id_to_word.setdefault(i, '<unknown>')\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \" we think VERY much of \".lower()\n",
    "words = sentence.split()\n",
    "\n",
    "# Pad or truncate the sentence to length 4\n",
    "if len(words) < 4:\n",
    "    words += [''] * (4 - len(words))\n",
    "else:\n",
    "    words = words[:4]\n",
    "\n",
    "# Convert the words to integer-encoded IDs\n",
    "word_ids = [word_to_id[word] for word in words]\n",
    "\n",
    "# Predict the target word\n",
    "x = np.array([word_ids])\n",
    "y_pred = cbow_model.predict(x)\n",
    "target_word_id = np.argmax(y_pred)\n",
    "target_word_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target word: i\n"
     ]
    }
   ],
   "source": [
    "target_word = id_to_word[target_word_id]\n",
    "print(\"Predicted target word:\", target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Predict the target word\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m prediction \u001b[39m=\u001b[39m cbow_model\u001b[39m.\u001b[39;49mpredict(context_vector)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Get the index of the predicted word\u001b[39;00m\n\u001b[0;32m      5\u001b[0m predicted_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(prediction)\n",
      "File \u001b[1;32mc:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0eb88nsy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\basel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "# Predict the target word\n",
    "prediction = cbow_model.predict(context_vector)\n",
    "\n",
    "# Get the index of the predicted word\n",
    "predicted_index = np.argmax(prediction)\n",
    "\n",
    "# Get the predicted word from the vocabulary\n",
    "predicted_word = text[predicted_index]\n",
    "\n",
    "print(\"The predicted next word is:\", predicted_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
